import os
from typing import List, Dict, Optional, Any
from datetime import datetime
import time
from google.oauth2 import service_account
from googleapiclient.discovery import build
from src.monitor.monitor import Monitor
import re
import time
import threading

class SpreadsheetManager:
    def __init__(self):
        self.monitor = Monitor()
        self.spreadsheet_id = os.getenv('GOOGLE_SHEETS_ID')
        
        # ã‚·ãƒ¼ãƒˆåã®å®šç¾©
        self.keyword_sheet = 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†'
        self.product_sheet = 'å•†å“ç®¡ç†'
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        self._request_count = 0
        self._last_request_time = 0
        self._request_lock = threading.Lock()
        self._max_requests_per_minute = 50  # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ã‚’è€ƒæ…®ã—ã¦50ã«è¨­å®š
        self._min_request_interval = 1.2  # æœ€å°ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ï¼ˆç§’ï¼‰
        
        # Google Sheets APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.service = self._init_sheets_service()

    def _wait_for_rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ãŸå¾…æ©Ÿå‡¦ç†"""
        with self._request_lock:
            current_time = time.time()
            
            # å‰å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã‚‰æœ€å°é–“éš”ãŒçµŒéã—ã¦ã„ãªã„å ´åˆã¯å¾…æ©Ÿ
            time_since_last_request = current_time - self._last_request_time
            if time_since_last_request < self._min_request_interval:
                wait_time = self._min_request_interval - time_since_last_request
                print(f"[INFO] ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: {wait_time:.2f}ç§’å¾…æ©Ÿä¸­...")
                time.sleep(wait_time)
                current_time = time.time()
            
            # 1åˆ†é–“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆ60ç§’çµŒéã—ãŸå ´åˆï¼‰
            if current_time - self._last_request_time > 60:
                self._request_count = 0
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ãŒä¸Šé™ã«é”ã—ã¦ã„ã‚‹å ´åˆã¯å¾…æ©Ÿ
            if self._request_count >= self._max_requests_per_minute:
                wait_time = 60 - (current_time - self._last_request_time)
                if wait_time > 0:
                    print(f"[INFO] ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–: 1åˆ†é–“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸Šé™ã«é”ã—ãŸãŸã‚{wait_time:.2f}ç§’å¾…æ©Ÿä¸­...")
                    time.sleep(wait_time)
                    self._request_count = 0
            
            self._request_count += 1
            self._last_request_time = time.time()
            print(f"[DEBUG] APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ (ä»Šåˆ†ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {self._request_count}/{self._max_requests_per_minute})")

    def _init_sheets_service(self):
        """Google Sheets APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            # Google Sheets APIã®ã‚¹ã‚³ãƒ¼ãƒ—ã‚’è¨­å®š
            SCOPES = ['https://www.googleapis.com/auth/spreadsheets']

            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            credentials_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')

            if not credentials_path:
                # ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
                current_dir = os.path.dirname(__file__)
                credentials_path = os.path.join(current_dir, '..', '..', 'credentials.json')
                print(f"[INFO] ç’°å¢ƒå¤‰æ•° GOOGLE_APPLICATION_CREDENTIALS ãŒæœªè¨­å®šã®ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™: {credentials_path}")

            # ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–
            credentials_path = os.path.normpath(credentials_path)

            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
            if not os.path.exists(credentials_path):
                raise FileNotFoundError(f"ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {credentials_path}")

            credentials = service_account.Credentials.from_service_account_file(
                credentials_path, scopes=SCOPES)

            service = build('sheets', 'v4', credentials=credentials)
            print("[INFO] Google Sheets APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«æˆåŠŸ")
            return service
        except Exception as e:
            self.monitor.log_error(f"Google Sheets APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—: {str(e)}")
            return None

    def _get_sheet_values(self, sheet_name: str, range_name: str, value_render_option: str = 'FORMATTED_VALUE') -> List[List]:
        """ã‚·ãƒ¼ãƒˆã®å€¤ã‚’å–å¾—"""
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            self._wait_for_rate_limit()
            
            result = self.service.spreadsheets().values().get(
                spreadsheetId=self.spreadsheet_id,
                range=f'{sheet_name}!{range_name}',
                valueRenderOption=value_render_option
            ).execute()
            values = result.get('values', [])
            
            # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’ç°¡ç•¥åŒ–ï¼ˆå¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã®å ´åˆï¼‰
            if len(values) > 10:
                print(f"Debug in _get_sheet_values: sheet_name={sheet_name}, range_name={range_name}, rows_count={len(values)}")
            else:
                print(f"Debug in _get_sheet_values: sheet_name={sheet_name}, range_name={range_name}, values={values}")

            return values
        except Exception as e:
            self.monitor.log_error(f"ã‚·ãƒ¼ãƒˆã®å€¤ã®å–å¾—ã«å¤±æ•—: {str(e)}")
            return []

    def _update_sheet_values(self, sheet_name: str, range_name: str, values: List[List]) -> bool:
        """ã‚·ãƒ¼ãƒˆã®å€¤ã‚’æ›´æ–°"""
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            self._wait_for_rate_limit()
            
            body = {'values': values}
            # HYPERLINKé–¢æ•°ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°USER_ENTEREDã€ãªã‘ã‚Œã°RAW
            value_input_option = 'USER_ENTERED' if any(
                any(isinstance(cell, str) and cell.startswith('=HYPERLINK(') for cell in row)
                for row in values
            ) else 'RAW'
            self.service.spreadsheets().values().update(
                spreadsheetId=self.spreadsheet_id,
                range=f'{sheet_name}!{range_name}',
                valueInputOption=value_input_option,
                body=body
            ).execute()
            return True
        except Exception as e:
            self.monitor.log_error(f"ã‚·ãƒ¼ãƒˆã®å€¤ã®æ›´æ–°ã«å¤±æ•—: {str(e)}")
            return False

    def get_active_keywords(self) -> List[Dict]:
        """å‡¦ç†å¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—"""
        try:
            # ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.keyword_sheet, 'A:G')
            if not values:
                return []

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’å–å¾—
            headers = values[0]
            
            # å‡¦ç†å¯¾è±¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            active_keywords = []
            processed_count = 0
            skipped_count = 0
            
            for row_index, row in enumerate(values[1:]):  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                # ç©ºè¡Œã‚„ä¸å®Œå…¨ãªè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                if len(row) < 4 or not any(row):
                    skipped_count += 1
                    continue
                
                processed_count += 1
                
                # å‡¦ç†ãƒ•ãƒ©ã‚°ãŒONï¼ˆTrueï¼‰ã®å ´åˆã®ã¿å‡¦ç†å¯¾è±¡ã¨ã™ã‚‹
                processed_flag_raw = row[0] if len(row) > 0 else ''
                processed_flag = str(processed_flag_raw).strip().lower()
                
                # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’æœ€å°é™ã«ï¼ˆTRUEã®å ´åˆã®ã¿ï¼‰
                if processed_flag in ['true', 'on', '1', 'yes', 'âœ“', 'ãƒã‚§ãƒƒã‚¯', 'checked', 'âœ…']:
                    print(f"Debug in get_active_keywords: Found active keyword at row {row_index + 2}: {row}")
                    
                    keyword_data = {
                        'original_work': row[1] if len(row) > 1 else '',           # åŸä½œå
                        'character_name': row[2] if len(row) > 2 else '',          # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
                        'keyword': row[3] if len(row) > 3 else '',                 # FANZAæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                        'last_processed': row[4] if len(row) > 4 else None,  # æœ€çµ‚å‡¦ç†æ—¥æ™‚
                        'last_result': row[5] if len(row) > 5 else None,    # æœ€çµ‚å‡¦ç†çµæœ
                        'notes': row[6] if len(row) > 6 else None           # å‚™è€ƒ
                    }
                    
                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚«ãƒ©ãƒ ãŒç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                    if keyword_data['keyword']:
                        active_keywords.append(keyword_data)
                        print(f"Debug in get_active_keywords: Added keyword: '{keyword_data['keyword']}' for {keyword_data['character_name']}")
            
            print(f"Debug in get_active_keywords: Processed {processed_count} rows, skipped {skipped_count} empty rows")
            print(f"Debug in get_active_keywords: Final active_keywords count: {len(active_keywords)}")

            return active_keywords

        except Exception as e:
            self.monitor.log_error(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å–å¾—ã«å¤±æ•—: {str(e)}")
            return []

    def update_keyword_status(self, keyword: str, status: str, result: Optional[str] = None) -> bool:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡¦ç†çŠ¶æ…‹ã‚’æ›´æ–°"""
        try:
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.keyword_sheet, 'A:F')
            if not values:
                return False

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã™ã‚‹è¡Œã‚’æ¢ã™
            for i, row in enumerate(values[1:], start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if len(row) >= 3 and row[2] == keyword:
                    # æ›´æ–°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
                    update_range = f'D{i}:E{i}'
                    update_values = [[
                        datetime.now().isoformat(),  # æœ€çµ‚å‡¦ç†æ—¥æ™‚
                        status + (f": {result}" if result else "")  # æœ€çµ‚å‡¦ç†çµæœ
                    ]]
                    
                    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°
                    return self._update_sheet_values(self.keyword_sheet, update_range, update_values)
            
            return False

        except Exception as e:
            self.monitor.log_error(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®çŠ¶æ…‹æ›´æ–°ã«å¤±æ•—: {str(e)}")
            return False

    def get_next_keyword_to_process(self) -> Optional[Dict]:
        """æ¬¡ã«å‡¦ç†ã™ã¹ãã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—ï¼ˆæœ€çµ‚å‡¦ç†æ—¥æ™‚ã®å¤ã„é †ï¼‰"""
        try:
            # Aåˆ—ãŒTRUEã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
            active_keywords = self.get_active_keywords()
            if not active_keywords:
                print("Debug: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            # æœ€çµ‚å‡¦ç†æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæœªå‡¦ç†ã¾ãŸã¯å¤ã„é †ï¼‰
            def parse_datetime(date_str):
                if not date_str or date_str.strip() == '':
                    return datetime.min  # æœªå‡¦ç†ã®å ´åˆã¯æœ€ã‚‚å¤ã„æ—¥æ™‚ã¨ã—ã¦æ‰±ã†
                try:
                    # ISOå½¢å¼ã§è§£æã‚’è©¦è¡Œ
                    return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                except ValueError:
                    try:
                        # ä¸€èˆ¬çš„ãªæ—¥æ™‚å½¢å¼ã§è§£æã‚’è©¦è¡Œ
                        return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
                    except ValueError:
                        return datetime.min  # ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆã¯æœ€ã‚‚å¤ã„æ—¥æ™‚ã¨ã—ã¦æ‰±ã†
            
            # æœ€çµ‚å‡¦ç†æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
            sorted_keywords = sorted(active_keywords, key=lambda x: parse_datetime(x.get('last_processed', '')))
            
            # æœ€ã‚‚å¤ã„ï¼ˆã¾ãŸã¯æœªå‡¦ç†ã®ï¼‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¿”ã™
            next_keyword = sorted_keywords[0]
            print(f"Debug: æ¬¡ã®å‡¦ç†å¯¾è±¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {next_keyword['keyword']} (æœ€çµ‚å‡¦ç†: {next_keyword.get('last_processed', 'æœªå‡¦ç†')})")
            
            return next_keyword
            
        except Exception as e:
            self.monitor.log_error(f"æ¬¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—ã«å¤±æ•—: {str(e)}")
            return None

    def update_keyword_last_processed(self, keyword: str, character_name: str = None) -> bool:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æœ€çµ‚å‡¦ç†æ—¥æ™‚ã‚’æ›´æ–°"""
        try:
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.keyword_sheet, 'A:G')
            if not values:
                return False

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¾ãŸã¯ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã«ä¸€è‡´ã™ã‚‹è¡Œã‚’æ¢ã™
            for i, row in enumerate(values[1:], start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                row_keyword = row[3] if len(row) > 3 else ''
                row_character = row[2] if len(row) > 2 else ''
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¾ãŸã¯ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã§ä¸€è‡´åˆ¤å®š
                if (keyword and row_keyword == keyword) or (character_name and row_character == character_name):
                    # Eåˆ—ï¼ˆæœ€çµ‚å‡¦ç†æ—¥æ™‚ï¼‰ã‚’æ›´æ–°
                    update_range = f'E{i}'
                    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    update_values = [[current_time]]
                    
                    print(f"Debug: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' (ã‚­ãƒ£ãƒ©: {character_name}) ã®æœ€çµ‚å‡¦ç†æ—¥æ™‚ã‚’æ›´æ–°: {current_time}")
                    
                    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°
                    return self._update_sheet_values(self.keyword_sheet, update_range, update_values)
            
            print(f"Warning: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' (ã‚­ãƒ£ãƒ©: {character_name}) ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False

        except Exception as e:
            self.monitor.log_error(f"æœ€çµ‚å‡¦ç†æ—¥æ™‚ã®æ›´æ–°ã«å¤±æ•—: {str(e)}")
            return False

    def get_sequential_keywords_for_48posts(self, start_count: int = 48) -> List[Dict]:
        """48ä»¶æŠ•ç¨¿ç”¨ã®é †æ¬¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—"""
        try:
            # Aåˆ—ãŒTRUEã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å–å¾—
            active_keywords = self.get_active_keywords()
            if not active_keywords:
                return []
            
            # æœ€çµ‚å‡¦ç†æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆå¤ã„é †ï¼‰
            def parse_datetime(date_str):
                if not date_str or date_str.strip() == '':
                    return datetime.min
                try:
                    return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                except ValueError:
                    try:
                        return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
                    except ValueError:
                        return datetime.min
            
            sorted_keywords = sorted(active_keywords, key=lambda x: parse_datetime(x.get('last_processed', '')))
            
            # å¿…è¦ãªä»¶æ•°åˆ†ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¾ªç’°ã—ã¦å–å¾—
            result_keywords = []
            keyword_count = len(sorted_keywords)
            
            if keyword_count == 0:
                return []
            
            for i in range(start_count):
                keyword_index = i % keyword_count  # å¾ªç’°ã•ã›ã‚‹
                result_keywords.append(sorted_keywords[keyword_index])
            
            print(f"Debug: 48ä»¶æŠ•ç¨¿ç”¨ã« {len(result_keywords)} ä»¶ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æº–å‚™ã—ã¾ã—ãŸ")
            return result_keywords
            
        except Exception as e:
            self.monitor.log_error(f"é †æ¬¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—ã«å¤±æ•—: {str(e)}")
            return []

    def _convert_product_id_to_url(self, product_id: str) -> str:
        """
        å•†å“IDã‚’FANZAã®å•†å“è©³ç´°URLå½¢å¼ã«å¤‰æ›ã™ã‚‹ã€‚
        ç°¡æ˜“çš„ãªå¤‰æ›ã§ã‚ã‚Šã€ã‚µãƒ¼ãƒ“ã‚¹ã‚„ãƒ•ãƒ­ã‚¢ã«ã‚ˆã£ã¦ã¯ç•°ãªã‚‹å½¢å¼ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
        """
        # ä»®ã«åŒäºº(digital/doujin)ã®URLå½¢å¼ã«å¤‰æ›
        return f"https://www.dmm.co.jp/dc/doujin/-/detail/=/cid={product_id}/"

    def extract_product_code(self, product_identifier: str) -> Optional[str]:
        """
        å•†å“URLã¾ãŸã¯HYPERLINKå½¢å¼ã‹ã‚‰å“ç•ªï¼ˆcidï¼‰ã‚’æŠ½å‡ºã™ã‚‹
        
        Args:
            product_identifier: å•†å“URLã¾ãŸã¯HYPERLINKå½¢å¼ã®æ–‡å­—åˆ—
            
        Returns:
            å“ç•ªï¼ˆcidï¼‰ã€‚æŠ½å‡ºã§ããªã„å ´åˆã¯None
        """
        if not product_identifier or not isinstance(product_identifier, str):
            return None
        
        # HYPERLINKå½¢å¼ã®å ´åˆã€URLã‚’æŠ½å‡º
        if product_identifier.startswith('=HYPERLINK('):
            match = re.search(r'=HYPERLINK\("([^"]+)"', product_identifier)
            if match:
                url = match.group(1)
            else:
                return None
        else:
            url = product_identifier
        
        # URLã‹ã‚‰å“ç•ªï¼ˆcidï¼‰ã‚’æŠ½å‡º
        match = re.search(r'cid=([^/&]+)', url)
        if match:
            return match.group(1)
        
        return None

    _product_codes_cache = None
    _cache_timestamp = None
    _cache_ttl = 300  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    
    def _get_cached_product_codes(self) -> set:
        """æ—¢å­˜å•†å“ã‚³ãƒ¼ãƒ‰ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãã§å–å¾—"""
        current_time = time.time()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã¯ãã‚Œã‚’è¿”ã™
        if (self._product_codes_cache is not None and 
            self._cache_timestamp is not None and 
            current_time - self._cache_timestamp < self._cache_ttl):
            return self._product_codes_cache
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°
        sheet_name = 'å•†å“ç®¡ç†'
        url_values = self._get_sheet_values(sheet_name, f'D:D')
        
        # HashSetã§O(1)æ¤œç´¢ã‚’å®Ÿç¾
        product_codes = set()
        for row in url_values:
            if row:
                code = self.extract_product_code(str(row[0]))
                if code:
                    product_codes.add(code.strip())
        
        self._product_codes_cache = product_codes
        self._cache_timestamp = current_time
        
        print(f"Debug: å•†å“ã‚³ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–° - {len(product_codes)}ä»¶")
        return product_codes
    
    def check_product_exists(self, product_identifier: str) -> bool:
        """
        å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã«ç‰¹å®šã®å•†å“ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
        å•†å“URLã¾ãŸã¯å•†å“IDã§ãƒã‚§ãƒƒã‚¯å¯èƒ½
        """
        # å“ç•ªã‚’æŠ½å‡º
        product_code = self.extract_product_code(product_identifier)
        if not product_code:
            print(f"Warning: æœ‰åŠ¹ãªå“ç•ªã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {product_identifier}")
            return False

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸHashSetã§O(1)æ¤œç´¢
        existing_codes = self._get_cached_product_codes()
        normalized_code = product_code.strip()
        
        return normalized_code in existing_codes
    
    def check_products_batch(self, product_identifiers: list) -> dict:
        """è¤‡æ•°å•†å“ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’ãƒãƒƒãƒå‡¦ç†"""
        # 1å›ã®ã‚·ãƒ¼ãƒˆå–å¾—ã§å…¨å•†å“ã‚’ãƒã‚§ãƒƒã‚¯
        existing_codes = self._get_cached_product_codes()
        
        results = {}
        for identifier in product_identifiers:
            code = self.extract_product_code(identifier)
            if code:
                results[identifier] = code.strip() in existing_codes
            else:
                results[identifier] = False
                
        return results

    def clear_product_cache(self):
        """å•†å“ã‚³ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self._product_codes_cache = None
        self._cache_timestamp = None
        print("Debug: å•†å“ã‚³ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

    def add_product(self, product_data: Dict[str, Any]) -> bool:
        """å•†å“æƒ…å ±ã‚’è¿½åŠ ï¼ˆå•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆ9ã‚«ãƒ©ãƒ å¯¾å¿œï¼‰"""
        try:
            # å•†å“URLãŒå•†å“IDã®ã‚ˆã†ã«è¦‹ãˆã‚‹å ´åˆã€URLã«å¤‰æ›ã—ã¦ä¿å­˜
            product_url = product_data.get('url', '')
            if product_url and not product_url.startswith("http"):
                product_data['url'] = self._convert_product_id_to_url(product_url)
            
            # ä¿å­˜ã™ã‚‹è¡Œãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆã‚·ãƒ¼ãƒˆã®ã‚«ãƒ©ãƒ é †ã«åˆã‚ã›ã‚‹ï¼‰
            # ã‚«ãƒ©ãƒ ã®é †ç•ª: æŠ•ç¨¿ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹, åŸä½œå, ã‚­ãƒ£ãƒ©å, å•†å“URL, å•†å“å, äºˆç´„æŠ•ç¨¿æ—¥æ™‚, è¨˜äº‹URL, æœ€çµ‚å‡¦ç†æ—¥æ™‚, ã‚¨ãƒ©ãƒ¼è©³ç´°

            # Dåˆ— (å•†å“URL): å“ç•ªè¡¨è¨˜ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯
            product_url = product_data.get('url', '')
            # HYPERLINKã‹ã‚‰å®Ÿéš›ã®URLã‚’æŠ½å‡ºã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹ãŒã€
            # ã“ã“ã§ã¯product_data['å•†å“URL']ãŒæ—¢ã« =HYPERLINK("URL", "TEXT") å½¢å¼ã‹ã€ç”Ÿã®URLã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®š
            actual_product_url = ''
            product_id_for_link = ''
            if isinstance(product_url, str) and product_url.startswith('=HYPERLINK("'):
                match = re.search(r'=HYPERLINK\("([^\"]+)\", \"([^\"]+)\"\)', product_url)
                if match:
                    actual_product_url = match.group(1)
                    product_id_for_link = match.group(2)
                else: # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯å…ƒã®å€¤ã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    actual_product_url = product_url 
            else:
                actual_product_url = product_url # æ•°å¼ã§ãªã‘ã‚Œã°ãã®ã¾ã¾URLã¨ã¿ãªã™
                # product_id_for_link ã¯åˆ¥é€” product_data ã‹ã‚‰å–å¾—ã™ã‚‹ã‹ã€URLã‹ã‚‰æŠ½å‡º
                product_id_from_data = product_data.get('å“ç•ª') # ä»®ã®ã‚­ãƒ¼ã€å®Ÿéš›ã«ã¯å­˜åœ¨ã—ãªã„ã‹ã‚‚
                if product_id_from_data:
                    product_id_for_link = product_id_from_data
                elif actual_product_url:
                    product_id_for_link = self.extract_product_code(actual_product_url)
            
            escaped_actual_product_url = actual_product_url.replace('"', '""')
            escaped_product_id_for_link = product_id_for_link.replace('"', '""')
            product_url_cell = f'=HYPERLINK("{escaped_actual_product_url}", "{escaped_product_id_for_link}")' if escaped_actual_product_url and escaped_product_id_for_link else ''

            # Fåˆ— (äºˆç´„æŠ•ç¨¿æ—¥æ™‚) ãŠã‚ˆã³ Håˆ— (æœ€çµ‚å‡¦ç†æ—¥æ™‚): MM/DD hh:mm å½¢å¼
            reserve_date_str = product_data.get('reserve_date', '')
            try:
                # ISOå½¢å¼ãªã©datetimeã§è§£æå¯èƒ½ãªå½¢å¼ã‚’æƒ³å®š
                reserve_date_formatted = datetime.fromisoformat(reserve_date_str).strftime('%m/%d %H:%M') if reserve_date_str else ''
            except ValueError:
                reserve_date_formatted = reserve_date_str # è§£æå¤±æ•—æ™‚ã¯å…ƒã®æ–‡å­—åˆ—ã‚’ãã®ã¾ã¾ä½¿ç”¨

            last_processed_str = product_data.get('last_processed', '')
            try:
                # ISOå½¢å¼ãªã©datetimeã§è§£æå¯èƒ½ãªå½¢å¼ã‚’æƒ³å®š
                last_processed_formatted = datetime.fromisoformat(last_processed_str).strftime('%m/%d %H:%M') if last_processed_str else ''
            except ValueError:
                last_processed_formatted = last_processed_str # è§£æå¤±æ•—æ™‚ã¯å…ƒã®æ–‡å­—åˆ—ã‚’ãã®ã¾ã¾ä½¿ç”¨

            # Gåˆ— (è¨˜äº‹URL): è¨˜äº‹IDè¡¨è¨˜ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯
            article_url = product_data.get('post_url', '')
            actual_article_url = ''
            article_id_for_link = ''

            if isinstance(article_url, str) and article_url.startswith('=HYPERLINK("'):
                match = re.search(r'=HYPERLINK\("([^\"]+)\", \"([^\"]+)\"\)', article_url)
                if match:
                    actual_article_url = match.group(1)
                    article_id_for_link = match.group(2)
                else: # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã¯å…ƒã®å€¤ã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    actual_article_url = article_url
            else:
                actual_article_url = article_url # æ•°å¼ã§ãªã‘ã‚Œã°ãã®ã¾ã¾URLã¨ã¿ãªã™
                # article_id_for_link ã¯åˆ¥é€” product_data ã‹ã‚‰å–å¾—ã™ã‚‹ã‹ã€URLã‹ã‚‰æŠ½å‡º
                post_id_from_data = product_data.get('è¨˜äº‹ID') # ä»®ã®ã‚­ãƒ¼
                if post_id_from_data:
                    article_id_for_link = str(post_id_from_data)
                elif actual_article_url:
                    # URLã‹ã‚‰è¨˜äº‹IDã‚’æŠ½å‡ºï¼ˆ/?p=ID ã¾ãŸã¯ /archives/ID å½¢å¼ã‚’æƒ³å®šï¼‰
                    match_p = re.search(r'/?p=(\\d+)', actual_article_url)
                    if match_p:
                        article_id_for_link = match_p.group(1)
                    else:
                        match_arc = re.search(r'/archives/(\\d+)', actual_article_url)
                        if match_arc:
                            article_id_for_link = match_arc.group(1)

            escaped_actual_article_url = actual_article_url.replace('"', '""')
            escaped_article_id_for_link = article_id_for_link.replace('"', '""')
            article_url_cell = f'=HYPERLINK("{escaped_actual_article_url}", "{escaped_article_id_for_link}")' if escaped_actual_article_url and escaped_article_id_for_link else ''

            row_data = [
                product_data.get('status', ''), # A: æŠ•ç¨¿ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
                product_data.get('original_work', ''), # B: åŸä½œå
                product_data.get('character_name', ''), # C: ã‚­ãƒ£ãƒ©å
                product_url_cell,                       # D: å•†å“URL (å“ç•ªè¡¨è¨˜+ãƒªãƒ³ã‚¯)
                product_data.get('title', ''), # E: FANZAã®å•†å“ã‚¿ã‚¤ãƒˆãƒ«
                reserve_date_formatted,                 # F: äºˆç´„æŠ•ç¨¿æ—¥æ™‚ (MM/DD hh:mm)
                article_url_cell,                          # G: è¨˜äº‹URL (è¨˜äº‹IDè¡¨è¨˜+ãƒªãƒ³ã‚¯)
                last_processed_formatted,               # H: æœ€çµ‚å‡¦ç†æ—¥æ™‚ (MM/DD hh:mm)
                product_data.get('error_details', ''), # I: ã‚¨ãƒ©ãƒ¼è©³ç´°
            ]

            sheet_name = 'å•†å“ç®¡ç†'
            # æœ«å°¾ã«è¡Œã‚’è¿½åŠ 
            range_name = f'{sheet_name}!A:I' # 9ã‚«ãƒ©ãƒ åˆ†
            
            print(f"Debug in add_product: Attempting to append row: {row_data}")

            try:
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                self._wait_for_rate_limit()
                
                self.service.spreadsheets().values().append(
                    spreadsheetId=self.spreadsheet_id,
                    range=range_name,
                    valueInputOption='USER_ENTERED',
                    body={
                        'values': [row_data]
                    }
                ).execute()
                
                # å•†å“è¿½åŠ å¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
                self.clear_product_cache()
                return True
            except Exception as e:
                self.monitor.log_error(f"å•†å“ã®è¿½åŠ ã«å¤±æ•—: {str(e)}")
                return False

        except Exception as e:
            self.monitor.log_error(f"å•†å“ã®è¿½åŠ ã«å¤±æ•—: {str(e)}")
            return False

    def add_products_batch(self, products_data: List[Dict[str, Any]]) -> bool:
        """
        å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã«è¤‡æ•°ã®å•†å“ã‚’ä¸€æ‹¬è¿½åŠ ï¼ˆé‡è¤‡å•†å“ã®è‡ªå‹•å‰Šé™¤æ©Ÿèƒ½ä»˜ãï¼‰
        
        Args:
            products_data: å•†å“ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            bool: è¿½åŠ ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        try:
            if not products_data:
                return True
            
            # ã€æ–°æ©Ÿèƒ½ã€‘é‡è¤‡å•†å“ã®è‡ªå‹•å‰Šé™¤
            print("ğŸ” é‡è¤‡å•†å“ã®æ¤œå‡ºã¨å‰Šé™¤ã‚’é–‹å§‹...")
            deleted_count = self._remove_duplicate_products(products_data)
            if deleted_count > 0:
                print(f"âœ… {deleted_count}ä»¶ã®é‡è¤‡å•†å“ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            else:
                print("ğŸ“‹ å‰Šé™¤å¯¾è±¡ã®é‡è¤‡å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            # å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’è¡Œå½¢å¼ã«å¤‰æ›
            rows_data = []
            for product_data in products_data:
                # å•†å“URLãŒå•†å“IDã®ã‚ˆã†ã«è¦‹ãˆã‚‹å ´åˆã€URLã«å¤‰æ›ã—ã¦ä¿å­˜
                product_url = product_data.get('url', '')
                if product_url and not product_url.startswith("http"):
                    product_data['url'] = self._convert_product_id_to_url(product_url)
                
                # Dåˆ— (å•†å“URL): å“ç•ªè¡¨è¨˜ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯
                product_url = product_data.get('url', '')
                actual_product_url = ''
                product_id_for_link = ''
                
                if isinstance(product_url, str) and product_url.startswith('=HYPERLINK("'):
                    match = re.search(r'=HYPERLINK\("([^\"]+)\", \"([^\"]+)\"\)', product_url)
                    if match:
                        actual_product_url = match.group(1)
                        product_id_for_link = match.group(2)
                    else:
                        actual_product_url = product_url 
                else:
                    actual_product_url = product_url
                    product_id_from_data = product_data.get('å“ç•ª')
                    if product_id_from_data:
                        product_id_for_link = product_id_from_data
                    elif actual_product_url:
                        product_id_for_link = self.extract_product_code(actual_product_url)
                
                escaped_actual_product_url = actual_product_url.replace('"', '""')
                escaped_product_id_for_link = product_id_for_link.replace('"', '""')
                product_url_cell = f'=HYPERLINK("{escaped_actual_product_url}", "{escaped_product_id_for_link}")' if escaped_actual_product_url and escaped_product_id_for_link else ''

                row_data = [
                    product_data.get('status', 'æœªå‡¦ç†'),
                    product_data.get('original_work', ''),
                    product_data.get('character_name', ''),
                    product_url_cell,
                    product_data.get('title', ''),
                    product_data.get('reserve_date', ''),
                    product_data.get('post_url', ''),
                    product_data.get('last_processed', ''),
                    product_data.get('error_details', '')
                ]
                rows_data.append(row_data)
            
            print(f"Debug in add_products_batch: Attempting to append {len(rows_data)} rows")
            
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            self._wait_for_rate_limit()
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¡Œã‚’ä¸€æ‹¬è¿½åŠ 
            body = {'values': rows_data}
            
            # HYPERLINKé–¢æ•°ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            value_input_option = 'USER_ENTERED' if any(
                any(isinstance(cell, str) and cell.startswith('=HYPERLINK(') for cell in row)
                for row in rows_data
            ) else 'RAW'
            
            self.service.spreadsheets().values().append(
                spreadsheetId=self.spreadsheet_id,
                range=f'{self.product_sheet}!A:I',
                valueInputOption=value_input_option,
                insertDataOption='INSERT_ROWS',
                body=body
            ).execute()
            
            print(f"Debug in add_products_batch: Successfully added {len(rows_data)} products")
            return True
            
        except Exception as e:
            self.monitor.log_error(f"å•†å“ã®ä¸€æ‹¬è¿½åŠ ã«å¤±æ•—: {str(e)}")
            return False

    def _remove_duplicate_products(self, new_products_data: List[Dict[str, Any]]) -> int:
        """
        æ–°å•†å“è¿½åŠ å‰ã«æ—¢å­˜ã®é‡è¤‡å•†å“ã‚’å‰Šé™¤ï¼ˆæœªå‡¦ç†å•†å“ã®ã¿å¯¾è±¡ï¼‰
        
        Args:
            new_products_data: è¿½åŠ äºˆå®šã®æ–°å•†å“ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
            
        Returns:
            int: å‰Šé™¤ã—ãŸå•†å“æ•°
        """
        try:
            # æ–°å•†å“ã®å“ç•ªãƒªã‚¹ãƒˆã‚’ä½œæˆ
            new_product_ids = set()
            for product_data in new_products_data:
                product_url = product_data.get('url', '')
                product_id = self.extract_product_code(product_url)
                if product_id:
                    new_product_ids.add(product_id)
            
            if not new_product_ids:
                return 0
            
            print(f"ğŸ” æ–°å•†å“ã®å“ç•ª: {list(new_product_ids)}")
            
            # æ—¢å­˜ã®å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.product_sheet, 'A2:I1000', value_render_option='FORMULA')
            if not values:
                return 0
            
            # å‰Šé™¤å¯¾è±¡å¤–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆå‡¦ç†æ¸ˆã¿å•†å“ã¯å‰Šé™¤ã—ãªã„ï¼‰
            protected_statuses = {
                'äºˆç´„æŠ•ç¨¿', 'æŠ•ç¨¿æ¸ˆã¿', 'æŠ•ç¨¿å®Œäº†', 'å…¬é–‹æ¸ˆã¿', 'å‡¦ç†æ¸ˆã¿', 
                'ä¸‹æ›¸ãä¿å­˜', 'ä¸‹æ›¸ã', 'draft', 'published', 'scheduled'
            }
            
            # é‡è¤‡å•†å“ã®è¡Œç•ªå·ã‚’ç‰¹å®šï¼ˆæœªå‡¦ç†ã®ã‚‚ã®ã®ã¿ï¼‰
            rows_to_delete = []
            for idx, row in enumerate(values, start=2):
                if len(row) < 4:
                    continue
                
                # Aåˆ—ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
                status = str(row[0]).strip() if row[0] else ''
                
                # å‡¦ç†æ¸ˆã¿å•†å“ã¯å‰Šé™¤å¯¾è±¡ã‹ã‚‰é™¤å¤–
                if status in protected_statuses:
                    continue
                
                # Dåˆ—ï¼ˆå•†å“URLï¼‰ã‹ã‚‰å“ç•ªã‚’æŠ½å‡º
                product_url = row[3] if len(row) > 3 else ''
                existing_product_id = self.extract_product_code(str(product_url))
                
                if existing_product_id in new_product_ids:
                    rows_to_delete.append({
                        'row_index': idx,
                        'product_id': existing_product_id,
                        'status': status,
                        'url': product_url
                    })
            
            if not rows_to_delete:
                return 0
            
            print(f"ğŸ—‘ï¸  å‰Šé™¤å¯¾è±¡ã®é‡è¤‡å•†å“ï¼ˆæœªå‡¦ç†ã®ã¿ï¼‰: {len(rows_to_delete)}ä»¶")
            for item in rows_to_delete:
                print(f"   Row {item['row_index']}: {item['product_id']} (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: '{item['status']}')")
            
            # è¡Œã‚’å¾Œã‚ã‹ã‚‰å‰Šé™¤ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãšã‚Œã‚’é˜²ããŸã‚ï¼‰
            rows_to_delete.sort(key=lambda x: x['row_index'], reverse=True)
            
            deleted_count = 0
            for item in rows_to_delete:
                try:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                    self._wait_for_rate_limit()
                    
                    # è¡Œã‚’å‰Šé™¤
                    self.service.spreadsheets().batchUpdate(
                        spreadsheetId=self.spreadsheet_id,
                        body={
                            'requests': [{
                                'deleteDimension': {
                                    'range': {
                                        'sheetId': self._get_sheet_id(self.product_sheet),
                                        'dimension': 'ROWS',
                                        'startIndex': item['row_index'] - 1,  # 0ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                                        'endIndex': item['row_index']
                                    }
                                }
                            }]
                        }
                    ).execute()
                    
                    print(f"âœ… å‰Šé™¤å®Œäº†: Row {item['row_index']} - {item['product_id']} (æœªå‡¦ç†)")
                    deleted_count += 1
                    
                except Exception as e:
                    print(f"âŒ å‰Šé™¤å¤±æ•—: Row {item['row_index']} - {item['product_id']}: {str(e)}")
            
            return deleted_count
            
        except Exception as e:
            print(f"âŒ é‡è¤‡å•†å“å‰Šé™¤å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return 0
    
    def cleanup_duplicate_products(self) -> int:
        """
        å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã‹ã‚‰é‡è¤‡å•†å“ã‚’ä¸€æ‹¬å‰Šé™¤ï¼ˆæœªå‡¦ç†ã®ã‚‚ã®ã®ã¿ï¼‰
        æ–°å•†å“è¿½åŠ ã«ä¾å­˜ã—ãªã„ç‹¬ç«‹ã—ãŸé‡è¤‡å‰Šé™¤æ©Ÿèƒ½
        
        Returns:
            int: å‰Šé™¤ã—ãŸå•†å“æ•°
        """
        try:
            print("ğŸ” å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã®é‡è¤‡å•†å“æ¤œå‡ºã‚’é–‹å§‹...")
            
            # æ—¢å­˜ã®å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.product_sheet, 'A2:I1000', value_render_option='FORMULA')
            if not values:
                print("ğŸ“‹ å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return 0
            
            # å‰Šé™¤å¯¾è±¡å¤–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼ˆå‡¦ç†æ¸ˆã¿å•†å“ã¯å‰Šé™¤ã—ãªã„ï¼‰
            protected_statuses = {
                'äºˆç´„æŠ•ç¨¿', 'æŠ•ç¨¿æ¸ˆã¿', 'æŠ•ç¨¿å®Œäº†', 'å…¬é–‹æ¸ˆã¿', 'å‡¦ç†æ¸ˆã¿', 
                'ä¸‹æ›¸ãä¿å­˜', 'ä¸‹æ›¸ã', 'draft', 'published', 'scheduled'
            }
            
            # å“ç•ªã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦é‡è¤‡ã‚’æ¤œå‡º
            product_groups = {}
            for idx, row in enumerate(values, start=2):
                if len(row) < 4:
                    continue
                
                # Aåˆ—ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
                status = str(row[0]).strip() if row[0] else ''
                
                # Dåˆ—ï¼ˆå•†å“URLï¼‰ã‹ã‚‰å“ç•ªã‚’æŠ½å‡º
                product_url = row[3] if len(row) > 3 else ''
                product_id = self.extract_product_code(str(product_url))
                
                if not product_id:
                    continue
                
                if product_id not in product_groups:
                    product_groups[product_id] = []
                
                product_groups[product_id].append({
                    'row_index': idx,
                    'product_id': product_id,
                    'status': status,
                    'url': product_url,
                    'protected': status in protected_statuses
                })
            
            # é‡è¤‡å•†å“ã®å‰Šé™¤å¯¾è±¡ã‚’ç‰¹å®š
            rows_to_delete = []
            for product_id, group in product_groups.items():
                if len(group) <= 1:
                    continue  # é‡è¤‡ã—ã¦ã„ãªã„
                
                # ä¿è­·ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚‹ã‹ç¢ºèª
                protected_entries = [entry for entry in group if entry['protected']]
                unprotected_entries = [entry for entry in group if not entry['protected']]
                
                if protected_entries:
                    # ä¿è­·ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªãŒã‚ã‚‹å ´åˆã€æœªå‡¦ç†ã®ã‚¨ãƒ³ãƒˆãƒªã®ã¿å‰Šé™¤
                    rows_to_delete.extend(unprotected_entries)
                else:
                    # ä¿è­·ã•ã‚ŒãŸã‚¨ãƒ³ãƒˆãƒªãŒãªã„å ´åˆã€æœ€åˆã®ã‚¨ãƒ³ãƒˆãƒªä»¥å¤–ã‚’å‰Šé™¤
                    rows_to_delete.extend(group[1:])
            
            if not rows_to_delete:
                print("ğŸ“‹ å‰Šé™¤å¯¾è±¡ã®é‡è¤‡å•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return 0
            
            print(f"ğŸ—‘ï¸  é‡è¤‡å•†å“å‰Šé™¤å¯¾è±¡: {len(rows_to_delete)}ä»¶")
            for item in rows_to_delete:
                print(f"   Row {item['row_index']}: {item['product_id']} (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: '{item['status']}')")
            
            # å‰Šé™¤ã®ç¢ºèªï¼ˆãƒãƒƒãƒå‡¦ç†æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            if len(rows_to_delete) > 5:
                print(f"âš ï¸  {len(rows_to_delete)}ä»¶ã®å‰Šé™¤ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (è‡ªå‹•å®Ÿè¡Œä¸­ã®ãŸã‚ç¶šè¡Œ)")
            
            # è¡Œã‚’å¾Œã‚ã‹ã‚‰å‰Šé™¤ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãšã‚Œã‚’é˜²ããŸã‚ï¼‰
            rows_to_delete.sort(key=lambda x: x['row_index'], reverse=True)
            
            deleted_count = 0
            for item in rows_to_delete:
                try:
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                    self._wait_for_rate_limit()
                    
                    # è¡Œã‚’å‰Šé™¤
                    self.service.spreadsheets().batchUpdate(
                        spreadsheetId=self.spreadsheet_id,
                        body={
                            'requests': [{
                                'deleteDimension': {
                                    'range': {
                                        'sheetId': self._get_sheet_id(self.product_sheet),
                                        'dimension': 'ROWS',
                                        'startIndex': item['row_index'] - 1,  # 0ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
                                        'endIndex': item['row_index']
                                    }
                                }
                            }]
                        }
                    ).execute()
                    
                    print(f"âœ… å‰Šé™¤å®Œäº†: Row {item['row_index']} - {item['product_id']}")
                    deleted_count += 1
                    
                except Exception as e:
                    print(f"âŒ å‰Šé™¤å¤±æ•—: Row {item['row_index']} - {item['product_id']}: {str(e)}")
            
            print(f"âœ… é‡è¤‡å•†å“ã®å‰Šé™¤ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å‰Šé™¤ä»¶æ•°: {deleted_count}ä»¶")
            return deleted_count
            
        except Exception as e:
            print(f"âŒ é‡è¤‡å•†å“å‰Šé™¤å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return 0

    def _get_sheet_id(self, sheet_name: str) -> int:
        """
        ã‚·ãƒ¼ãƒˆåã‹ã‚‰ã‚·ãƒ¼ãƒˆIDã‚’å–å¾—
        
        Args:
            sheet_name: ã‚·ãƒ¼ãƒˆå
            
        Returns:
            int: ã‚·ãƒ¼ãƒˆID
        """
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            self._wait_for_rate_limit()
            
            spreadsheet = self.service.spreadsheets().get(
                spreadsheetId=self.spreadsheet_id
            ).execute()
            
            for sheet in spreadsheet['sheets']:
                if sheet['properties']['title'] == sheet_name:
                    return sheet['properties']['sheetId']
            
            raise ValueError(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
        except Exception as e:
            raise Exception(f"ã‚·ãƒ¼ãƒˆIDå–å¾—ã«å¤±æ•—: {str(e)}")

    def get_existing_product_codes(self) -> List[str]:
        """å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã‹ã‚‰æ—¢å­˜ã®å“ç•ªã‚’èª­ã¿è¾¼ã‚€"""
        try:
            sheet_name = 'å•†å“ç®¡ç†'
            # å•†å“URLã‚«ãƒ©ãƒ (Dåˆ—)ã‚’å–å¾—
            url_values = self._get_sheet_values(sheet_name, 'D:D')
            # URLã‹ã‚‰å“ç•ªã‚’æŠ½å‡º
            existing_product_codes = [self.extract_product_code(str(row[0])) for row in url_values if row]
            # ç©ºã®å“ç•ªã‚’é™¤å¤–
            existing_product_codes = [code for code in existing_product_codes if code]
            print(f"Debug: æ—¢å­˜ã®å“ç•ªãƒªã‚¹ãƒˆ: {existing_product_codes}")
            return existing_product_codes
        except Exception as e:
            self.monitor.log_error(f"å“ç•ªãƒªã‚¹ãƒˆã®å–å¾—ã«å¤±æ•—: {str(e)}")
            return []

    def update_post_url_by_product_code(self, product_code: str, post_id: str, wp_domain: str):
        """å“ç•ªã§è©²å½“è¡Œã‚’ç‰¹å®šã—ã€è¨˜äº‹URLã‚«ãƒ©ãƒ ã«WordPressè¨˜äº‹IDã®ãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ã‚’è¨˜éŒ²"""
        values = self._get_sheet_values(self.product_sheet, 'D2:D1000')  # å•†å“URLåˆ—ï¼ˆå“ç•ªãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯ï¼‰
        for idx, row in enumerate(values, start=2):
            if row and product_code in row[0]:
                post_url = f'https://{wp_domain}/?p={post_id}'
                post_cell = f'=HYPERLINK("{post_url}", "{post_id}")'
                # Gåˆ—ï¼ˆè¨˜äº‹URLã‚«ãƒ©ãƒ ï¼‰ã«è¨˜éŒ²
                update_range = f'G{idx}'
                self._update_sheet_values(self.product_sheet, update_range, [[post_cell]])
                break 

    def get_product_urls_from_keywords(self) -> List[str]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ãƒ¼ãƒˆã‹ã‚‰å‡¦ç†ãƒ•ãƒ©ã‚°ONã®FANZAæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å•†å“URLãƒªã‚¹ãƒˆã‚’å–å¾—"""
        values = self._get_sheet_values(self.keyword_sheet, 'A1:D1000')
        urls = []
        for row in values[1:]:
            if len(row) >= 4 and row[0].lower() in ['true', 'on', '1', 'yes']:
                keyword = row[3]
                # ã“ã“ã§FANZA APIã‚„æ¤œç´¢URLç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å‘¼ã³å‡ºã™æƒ³å®š
                # ä¾‹: https://www.dmm.co.jp/dc/doujin/-/list/=/keyword={keyword}/
                search_url = f'https://www.dmm.co.jp/dc/doujin/-/list/=/keyword={keyword}/'
                urls.append(search_url)
        return urls 

    def update_row(self, sheet_name: str, row_idx: int, row_data: List[str]) -> None:
        """
        æŒ‡å®šã•ã‚ŒãŸè¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹
        
        Args:
            sheet_name (str): ã‚·ãƒ¼ãƒˆå
            row_idx (int): æ›´æ–°ã™ã‚‹è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆ1å§‹ã¾ã‚Šï¼‰
            row_data (List[str]): æ›´æ–°ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
        """
        try:
            # Gåˆ—ï¼ˆè¨˜äº‹URL, row_data[6]ï¼‰ãŒ=HYPERLINK(ã§å§‹ã¾ã£ã¦ã„ãªã‘ã‚Œã°è‡ªå‹•ã§ãƒªãƒ³ã‚¯åŒ–
            if len(row_data) > 6 and row_data[6]:
                cell = row_data[6]
                if isinstance(cell, str) and not cell.startswith('=HYPERLINK('):
                    url = cell
                    # IDã¯URLã®æœ«å°¾ã®æ•°å­—ã‚„/?p=IDã€/archives/IDã‹ã‚‰æ¨æ¸¬
                    import re
                    post_id = ''
                    match = re.search(r'[?&]p=(\d+)', url)
                    if match:
                        post_id = match.group(1)
                    else:
                        match = re.search(r'/archives/(\d+)', url)
                        if match:
                            post_id = match.group(1)
                        else:
                            # æœ«å°¾ã®æ•°å­—
                            match = re.search(r'(\d+)(?:/)?$', url)
                            if match:
                                post_id = match.group(1)
                    if url and post_id:
                        escaped_url = url.replace('"', '""')
                        escaped_id = post_id.replace('"', '""')
                        row_data[6] = f'=HYPERLINK("{escaped_url}", "{escaped_id}")'
            range_name = f"{sheet_name}!A{row_idx}:I{row_idx}"
            body = {
                "values": [row_data]
            }
            self.service.spreadsheets().values().update(
                spreadsheetId=self.spreadsheet_id,
                range=range_name,
                valueInputOption="USER_ENTERED",
                body=body
            ).execute()
            print(f"Debug: Updated row {row_idx} in sheet {sheet_name}")
        except Exception as e:
            print(f"Error in update_row: {str(e)}") 

    def add_character_to_keywords(self, original_work: str, character_names: List[str]) -> bool:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ãƒ¼ãƒˆã«æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
        """
        try:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.keyword_sheet, 'A:C')
            if not values:
                print("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return False

            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            existing_characters = set()
            for row in values[1:]:
                if len(row) > 1:
                    existing_characters.add(row[1])  # æ—¢å­˜ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å

            # æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
            new_rows = []
            for char_name in character_names:
                if char_name not in existing_characters:
                    new_rows.append([True, original_work, char_name, char_name, '', ''])  # æ–°ã—ã„è¡Œãƒ‡ãƒ¼ã‚¿
                    existing_characters.add(char_name)

            # æ–°ã—ã„è¡Œã‚’ã‚·ãƒ¼ãƒˆã«è¿½åŠ 
            if new_rows:
                range_to_update = f'{self.keyword_sheet}!A{len(values) + 1}:F{len(values) + len(new_rows)}'
                body = {'values': new_rows}
                self.service.spreadsheets().values().update(
                    spreadsheetId=self.spreadsheet_id,
                    range=range_to_update,
                    valueInputOption='USER_ENTERED',
                    body=body
                ).execute()
                print(f"{len(new_rows)}ä»¶ã®æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ãƒ¼ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸã€‚")
                return True
            else:
                print("æ–°ã—ã„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return False

        except Exception as e:
            self.monitor.log_error(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã‚·ãƒ¼ãƒˆã¸ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±è¿½åŠ ã«å¤±æ•—: {str(e)}")
            return False

    def format_product_sheet(self) -> bool:
        """
        å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã®æ•´å½¢ã‚’è¡Œã†ï¼ˆå“ç•ªãƒ»æŠ•ç¨¿IDãƒªãƒ³ã‚¯åŒ–ãªã©ï¼‰
        
        Returns:
            bool: æ•´å½¢ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
        """
        try:
            print("å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã®æ•´å½¢ã‚’é–‹å§‹ã—ã¾ã™...")
            
            # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.product_sheet, 'A:I')
            if not values or len(values) <= 1:
                print("å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return True
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å‡¦ç†
            updated_rows = []
            for i, row in enumerate(values[1:], start=2):
                if len(row) < 4:
                    continue
                
                row_updated = False
                
                # Dåˆ—ï¼ˆå•†å“URLï¼‰ã®æ•´å½¢
                product_url = row[3] if len(row) > 3 else ''
                if product_url and not product_url.startswith('=HYPERLINK('):
                    # å“ç•ªã‚’æŠ½å‡º
                    product_code = self.extract_product_code(product_url)
                    if product_code:
                        # HYPERLINKã«å¤‰æ›
                        escaped_url = product_url.replace('"', '""')
                        escaped_code = product_code.replace('"', '""')
                        hyperlink_formula = f'=HYPERLINK("{escaped_url}", "{escaped_code}")'
                        row[3] = hyperlink_formula
                        row_updated = True

                # Gåˆ—ï¼ˆè¨˜äº‹URLï¼‰ã®æ•´å½¢
                article_url = row[6] if len(row) > 6 else ''
                if article_url and not article_url.startswith('=HYPERLINK('):
                    # è¨˜äº‹IDã‚’æŠ½å‡ºï¼ˆ/?p=ID ã¾ãŸã¯ /archives/ID å½¢å¼ï¼‰
                    import re
                    post_id = ''
                    match = re.search(r'[?&]p=(\d+)', article_url)
                    if match:
                        post_id = match.group(1)
                    else:
                        match = re.search(r'/archives/(\d+)', article_url)
                        if match:
                            post_id = match.group(1)
                        else:
                            # æœ«å°¾ã®æ•°å­—
                            match = re.search(r'(\d+)(?:/)?$', article_url)
                            if match:
                                post_id = match.group(1)
                    if article_url and post_id:
                        escaped_url = article_url.replace('"', '""')
                        escaped_id = post_id.replace('"', '""')
                        row[6] = f'=HYPERLINK("{escaped_url}", "{escaped_id}")'
                        row_updated = True
                
                # è¡ŒãŒæ›´æ–°ã•ã‚ŒãŸå ´åˆã®ã¿updated_rowsã«è¿½åŠ 
                if row_updated:
                    updated_rows.append((i, row))
            
            # æ›´æ–°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ¼ãƒˆã«åæ˜ 
            if updated_rows:
                for row_idx, row_data in updated_rows:
                    range_name = f'{self.product_sheet}!A{row_idx}:I{row_idx}'
                    self._update_sheet_values(self.product_sheet, f'A{row_idx}:I{row_idx}', [row_data])
                
                print(f"{len(updated_rows)}è¡Œã®å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã‚’æ•´å½¢ã—ã¾ã—ãŸã€‚")
            else:
                print("æ•´å½¢ãŒå¿…è¦ãªè¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            return True
            
        except Exception as e:
            self.monitor.log_error(f"å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã®æ•´å½¢ã«å¤±æ•—: {str(e)}")
            return False

    def get_last_scheduled_time(self) -> Optional[datetime]:
        """
        å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã®Fåˆ—ï¼ˆäºˆç´„æŠ•ç¨¿æ—¥æ™‚ï¼‰ã‹ã‚‰æœ€å¾Œã®äºˆç´„æŠ•ç¨¿æ™‚é–“ã‚’å–å¾—
        
        Returns:
            æœ€å¾Œã®äºˆç´„æŠ•ç¨¿æ™‚é–“ã€‚ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯None
        """
        try:
            # Fåˆ—ï¼ˆäºˆç´„æŠ•ç¨¿æ—¥æ™‚ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            values = self._get_sheet_values(self.product_sheet, 'F:F')
            if not values or len(values) <= 1:
                print("Debug: å•†å“ç®¡ç†ã‚·ãƒ¼ãƒˆã«äºˆç´„æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return None
            
            scheduled_times = []
            for i, row in enumerate(values[1:], start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if row and row[0]:  # Fåˆ—ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                    time_str = str(row[0]).strip()
                    if time_str:
                        try:
                            # MM/DD HH:MMå½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                            if '/' in time_str and ':' in time_str:
                                # ç¾åœ¨ã®å¹´ã‚’ä½¿ç”¨ã—ã¦datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                                current_year = datetime.now().year
                                # MM/DD HH:MMå½¢å¼ã‚’è§£æ
                                date_part, time_part = time_str.split(' ')
                                month, day = map(int, date_part.split('/'))
                                hour, minute = map(int, time_part.split(':'))
                                
                                scheduled_time = datetime(current_year, month, day, hour, minute)
                                scheduled_times.append(scheduled_time)
                                print(f"Debug: äºˆç´„æŠ•ç¨¿æ™‚é–“ã‚’è§£æ: {time_str} -> {scheduled_time}")
                        except (ValueError, IndexError) as e:
                            print(f"Debug: äºˆç´„æŠ•ç¨¿æ™‚é–“ã®è§£æã«å¤±æ•— (è¡Œ{i}): {time_str} - {str(e)}")
                            continue
            
            if not scheduled_times:
                print("Debug: æœ‰åŠ¹ãªäºˆç´„æŠ•ç¨¿æ™‚é–“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return None
            
            # æœ€æ–°ã®äºˆç´„æŠ•ç¨¿æ™‚é–“ã‚’è¿”ã™
            last_time = max(scheduled_times)
            print(f"Debug: æœ€å¾Œã®äºˆç´„æŠ•ç¨¿æ™‚é–“: {last_time}")
            return last_time
            
        except Exception as e:
            self.monitor.log_error(f"æœ€å¾Œã®äºˆç´„æŠ•ç¨¿æ™‚é–“ã®å–å¾—ã«å¤±æ•—: {str(e)}")
            return None